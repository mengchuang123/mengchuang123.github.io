---
layout: homepage
---

## About Me

I am a second year graduate student majoring in computer science at Peking University, mainly focusing on foundational large model, including the **pre/post-training and RLHF of large vision models (VLM) and long-context of large language models (LLM)**.

## Research Interests

- **Multimodal Large Language Model:** Unified Understanding and Generation, SFT, RLHF, Reasoning <span style="color:red">**[[QwenVLo](https://qwenlm.github.io/blog/qwen-vlo), [VARGPT](https://github.com/VARGPT-family)]**</span>
- **Large Language Model:** Long Context <span style="color:red">**[[Doubao](https://www.doubao.com/chat/)]**</span>

  
{% include_relative _includes/services.md %}


## News

- **[Jun. 2025]** Our **QwenVLo** preview version can available for you to experience at [QwenVLo](https://qwenlm.github.io/blog/qwen-vlo/).
- **[Apr. 2025]** Open source training code and models of **VARGPT-v1.1** at [github](https://github.com/VARGPT-family/VARGPT-v1.1) and [Huggingface](https://huggingface.co/VARGPT-family). **Total GitHub stars exceed ~600**.
- **[Feb. 2025]** Our works **VASparse** is accepted for **CVPR 2025**. Work is continuously being updated at [github](https://github.com/mengchuang123/VASparse-github) .
- **[Jan. 2025]** Our code, model and paper about unified understanding and generation **VARGPT-v1** has been released.
- **[Jan. 2025]** Our work on CoT Distillation initially completed in Feb. 2024 is accepted for **ICLR 2025**.
- **[Dec. 2024]** Our paper and code about Hallucination Mitigation for MLLMs **VASparse** has been released.


{% include_relative _includes/preprint.md %}

{% include_relative _includes/publications.md %}


